services:
  namenode:
    build:
      context: ./namenode
    container_name: namenode
    hostname: namenode
    ports:
      - "9870:9870"
      - "8088:8088"
    volumes:
      - namenode_data:/hadoopdata
    environment:
      - HDFS_NAMENODE_USER=root
      - HDFS_DATANODE_USER=root
      - HDFS_SECONDARYNAMENODE_USER=root
      - YARN_RESOURCEMANAGER_USER=root
      - YARN_NODEMANAGER_USER=root
    entrypoint: ["/entrypoint.sh"]
    networks:
      - hadoop-net

  datanode1:
    build:
      context: ./datanode
    container_name: datanode1
    hostname: datanode1
    depends_on:
      - namenode
    volumes:
      - datanode1_data:/hadoopdata
    environment:
      - HDFS_NAMENODE_USER=root
      - HDFS_DATANODE_USER=root
      - HDFS_SECONDARYNAMENODE_USER=root
      - YARN_RESOURCEMANAGER_USER=root
      - YARN_NODEMANAGER_USER=root
    entrypoint: ["/entrypoint.sh"]
    networks:
      - hadoop-net

  datanode2:
    build:
      context: ./datanode
    container_name: datanode2
    hostname: datanode2
    depends_on:
      - namenode
    volumes:
      - datanode2_data:/hadoopdata
    environment:
      - HDFS_NAMENODE_USER=root
      - HDFS_DATANODE_USER=root
      - HDFS_SECONDARYNAMENODE_USER=root
      - YARN_RESOURCEMANAGER_USER=root
      - YARN_NODEMANAGER_USER=root
    entrypoint: ["/entrypoint.sh"]
    networks:
      - hadoop-net

  spark:
    build:
      context: ./spark
    container_name: spark-master
    hostname: spark-master
    depends_on:
      - namenode
      - datanode1
      - datanode2
      - elasticsearch
    ports:
      - "8080:8080"
      - "7077:7077" 
    environment:
      - SPARK_MASTER_HOST=0.0.0.0
      - SPARK_HOME=/spark
      - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
    volumes:
      - ./spark/app:/app 
      - spark_data:/spark
    entrypoint: ["/entrypoint.sh"]
    networks:
      - hadoop-net

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.10.1
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ports:
      - "9200:9200"
    networks:
      - hadoop-net

  kibana:
    image: docker.elastic.co/kibana/kibana:7.10.1
    container_name: kibana
    depends_on:
      - elasticsearch
    ports:
      - "5601:5601"
    networks:
      - hadoop-net

  hbase:
    image: harisekhon/hbase
    container_name: hbase
    hostname: hbase
    environment:
      - HBASE_MANAGES_ZK=true
      - HDFS_ROOT_USER=root
    ports:
      - "16010:16010"
      - "2181:2181" 
    depends_on:
      - namenode
      - datanode1
      - datanode2
    networks:
      - hadoop-net

  postgresql:
    image: postgres:15
    container_name: postgres
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: your_user
      POSTGRES_PASSWORD: your_password
      POSTGRES_DB: your_database
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - hadoop-net

volumes:
  namenode_data:
  datanode1_data:
  datanode2_data:
  spark_data:
  postgres_data:


networks:
  hadoop-net:
